# Generated SBE (Simple Binary Encoding) message codec
# Code generated by SBE. DO NOT EDIT.

export TensorStreamHeaderMessage, TensorStreamHeaderMessageDecoder, TensorStreamHeaderMessageEncoder
abstract type TensorStreamHeaderMessage{T} end

struct TensorStreamHeaderMessageDecoder{T<:AbstractArray{UInt8}} <: TensorStreamHeaderMessage{T}
    buffer::T
    offset::Int64
    position_ptr::Base.RefValue{Int64}
    acting_block_length::UInt16
    acting_version::UInt16
    function TensorStreamHeaderMessageDecoder(buffer::T, offset::Integer, position_ptr::Ref{Int64},
        acting_block_length::Integer, acting_version::Integer) where {T}
        position_ptr[] = offset + acting_block_length
        new{T}(buffer, offset, position_ptr, acting_block_length, acting_version)
    end
end

struct TensorStreamHeaderMessageEncoder{T<:AbstractArray{UInt8},HasSbeHeader} <: TensorStreamHeaderMessage{T}
    buffer::T
    offset::Int64
    position_ptr::Base.RefValue{Int64}
    function TensorStreamHeaderMessageEncoder(buffer::T, offset::Integer,
        position_ptr::Ref{Int64}, hasSbeHeader::Bool=false) where {T}
        position_ptr[] = offset + 74
        new{T,hasSbeHeader}(buffer, offset, position_ptr)
    end
end

@inline function TensorStreamHeaderMessageDecoder(buffer::AbstractArray, offset::Integer=0;
    position_ptr::Base.RefValue{Int64}=Ref(0),
    header::MessageHeader=MessageHeader(buffer, offset))
    if templateId(header) != UInt16(0xe) || schemaId(header) != UInt16(0x1)
        throw(DomainError("Template id or schema id mismatch"))
    end
    TensorStreamHeaderMessageDecoder(buffer, offset + sbe_encoded_length(header), position_ptr,
        blockLength(header), version(header))
end
@inline function TensorStreamHeaderMessageEncoder(buffer::AbstractArray, offset::Integer=0;
    position_ptr::Base.RefValue{Int64}=Ref(0),
    header::MessageHeader=MessageHeader(buffer, offset))
    blockLength!(header, UInt16(0x4a))
    templateId!(header, UInt16(0xe))
    schemaId!(header, UInt16(0x1))
    version!(header, UInt16(0x0))
    TensorStreamHeaderMessageEncoder(buffer, offset + sbe_encoded_length(header), position_ptr, true)
end
sbe_buffer(m::TensorStreamHeaderMessage) = m.buffer
sbe_offset(m::TensorStreamHeaderMessage) = m.offset
sbe_position_ptr(m::TensorStreamHeaderMessage) = m.position_ptr
sbe_position(m::TensorStreamHeaderMessage) = m.position_ptr[]
sbe_position!(m::TensorStreamHeaderMessage, position) = m.position_ptr[] = position
sbe_block_length(::TensorStreamHeaderMessage) = UInt16(0x4a)
sbe_block_length(::Type{<:TensorStreamHeaderMessage}) = UInt16(0x4a)
sbe_template_id(::TensorStreamHeaderMessage) = UInt16(0xe)
sbe_template_id(::Type{<:TensorStreamHeaderMessage})  = UInt16(0xe)
sbe_schema_id(::TensorStreamHeaderMessage) = UInt16(0x1)
sbe_schema_id(::Type{<:TensorStreamHeaderMessage})  = UInt16(0x1)
sbe_schema_version(::TensorStreamHeaderMessage) = UInt16(0x0)
sbe_schema_version(::Type{<:TensorStreamHeaderMessage})  = UInt16(0x0)
sbe_semantic_type(::TensorStreamHeaderMessage) = ""
sbe_semantic_version(::TensorStreamHeaderMessage) = ""
sbe_acting_block_length(m::TensorStreamHeaderMessageDecoder) = m.acting_block_length
sbe_acting_block_length(::TensorStreamHeaderMessageEncoder) = UInt16(0x4a)
sbe_acting_version(m::TensorStreamHeaderMessageDecoder) = m.acting_version
sbe_acting_version(::TensorStreamHeaderMessageEncoder) = UInt16(0x0)
sbe_rewind!(m::TensorStreamHeaderMessage) = sbe_position!(m, m.offset + sbe_acting_block_length(m))
sbe_encoded_length(m::TensorStreamHeaderMessage) = sbe_position(m) - m.offset
@inline function sbe_decoded_length(m::TensorStreamHeaderMessage)
    skipper = TensorStreamHeaderMessageDecoder(sbe_buffer(m), sbe_offset(m), Ref(0),
        sbe_acting_block_length(m), sbe_acting_version(m))
    sbe_skip!(skipper)
    sbe_encoded_length(skipper)
end

Base.sizeof(m::TensorStreamHeaderMessage) = sbe_decoded_length(m)
function Base.convert(::Type{AbstractArray{UInt8}}, m::TensorStreamHeaderMessageEncoder{<:AbstractArray{UInt8},true})
    return view(m.buffer, m.offset+1-sbe_encoded_length(MessageHeader):m.offset+sbe_encoded_length(m))
end
function Base.convert(::Type{AbstractArray{UInt8}}, m::TensorStreamHeaderMessageEncoder{<:AbstractArray{UInt8},false})
    return view(m.buffer, m.offset+1:m.offset+sbe_encoded_length(m))
end

function header_meta_attribute(::TensorStreamHeaderMessage, meta_attribute)
    meta_attribute === :presence && return Symbol("required")
    return Symbol("")
end
header_id(::TensorStreamHeaderMessage) = UInt16(0x1)
header_since_version(::TensorStreamHeaderMessage) = UInt16(0x0)
header_in_acting_version(m::TensorStreamHeaderMessage) = sbe_acting_version(m) >= UInt16(0x0)
header_encoding_offset(::TensorStreamHeaderMessage) = 0
header(m::TensorStreamHeaderMessage) = SpidersMessageHeader(m.buffer, m.offset + 0, sbe_acting_version(m))

function sequencenumber_meta_attribute(::TensorStreamHeaderMessage, meta_attribute)
    meta_attribute === :presence && return Symbol("required")
    return Symbol("")
end
sequencenumber_id(::TensorStreamHeaderMessage) = UInt16(0x2)
sequencenumber_since_version(::TensorStreamHeaderMessage) = UInt16(0x0)
sequencenumber_in_acting_version(m::TensorStreamHeaderMessage) = sbe_acting_version(m) >= UInt16(0x0)
sequencenumber_encoding_offset(::TensorStreamHeaderMessage) = 64
sequencenumber_null_value(::TensorStreamHeaderMessage) = Int64(-9223372036854775808)
sequencenumber_min_value(::TensorStreamHeaderMessage) = Int64(-9223372036854775807)
sequencenumber_max_value(::TensorStreamHeaderMessage) = Int64(9223372036854775807)
sequencenumber_encoding_length(::TensorStreamHeaderMessage) = 8

@inline function sequencenumber(m::TensorStreamHeaderMessageDecoder)
    return decode_le(Int64, m.buffer, m.offset + 64)
end
@inline sequencenumber!(m::TensorStreamHeaderMessageEncoder, value) = encode_le(Int64, m.buffer, m.offset + 64, value)

function format_meta_attribute(::TensorStreamHeaderMessage, meta_attribute)
    meta_attribute === :presence && return Symbol("required")
    return Symbol("")
end
format_id(::TensorStreamHeaderMessage) = UInt16(0x3)
format_since_version(::TensorStreamHeaderMessage) = UInt16(0x0)
format_in_acting_version(m::TensorStreamHeaderMessage) = sbe_acting_version(m) >= UInt16(0x0)
format_encoding_offset(::TensorStreamHeaderMessage) = 72
format_encoding_length(::TensorStreamHeaderMessage) = 1
@inline function format(m::TensorStreamHeaderMessageDecoder, ::Type{Integer})
    return decode_le(Int8, m.buffer, m.offset + 72)
end
@inline function format(m::TensorStreamHeaderMessageDecoder)
    return Format.SbeEnum(decode_le(Int8, m.buffer, m.offset + 72))
end
@inline format!(m::TensorStreamHeaderMessageEncoder, value::Format.SbeEnum) = encode_le(Int8, m.buffer, m.offset + 72, Int8(value))

function majorOrder_meta_attribute(::TensorStreamHeaderMessage, meta_attribute)
    meta_attribute === :presence && return Symbol("required")
    return Symbol("")
end
majorOrder_id(::TensorStreamHeaderMessage) = UInt16(0x4)
majorOrder_since_version(::TensorStreamHeaderMessage) = UInt16(0x0)
majorOrder_in_acting_version(m::TensorStreamHeaderMessage) = sbe_acting_version(m) >= UInt16(0x0)
majorOrder_encoding_offset(::TensorStreamHeaderMessage) = 73
majorOrder_encoding_length(::TensorStreamHeaderMessage) = 1
@inline function majorOrder(m::TensorStreamHeaderMessageDecoder, ::Type{Integer})
    return decode_le(Int8, m.buffer, m.offset + 73)
end
@inline function majorOrder(m::TensorStreamHeaderMessageDecoder)
    return MajorOrder.SbeEnum(decode_le(Int8, m.buffer, m.offset + 73))
end
@inline majorOrder!(m::TensorStreamHeaderMessageEncoder, value::MajorOrder.SbeEnum) = encode_le(Int8, m.buffer, m.offset + 73, Int8(value))

export TensorStreamHeaderMessageSlice, TensorStreamHeaderMessageSliceDecoder, TensorStreamHeaderMessageSliceEncoder
abstract type TensorStreamHeaderMessageSlice{T} end

mutable struct TensorStreamHeaderMessageSliceDecoder{T<:AbstractArray{UInt8}} <: TensorStreamHeaderMessageSlice{T}
    const buffer::T
    offset::Int64
    const position_ptr::Base.RefValue{Int64}
    const block_length::UInt16
    const acting_version::UInt16
    const count::UInt16
    index::UInt16
    function TensorStreamHeaderMessageSliceDecoder(buffer::T, offset::Integer, position_ptr::Ref{Int64},
        block_length::Integer, acting_version::Integer,
        count::Integer, index::Integer) where {T}
        new{T}(buffer, offset, position_ptr, block_length, acting_version, count, index)
    end
end

mutable struct TensorStreamHeaderMessageSliceEncoder{T<:AbstractArray{UInt8}} <: TensorStreamHeaderMessageSlice{T}
    const buffer::T
    offset::Int64
    const position_ptr::Base.RefValue{Int64}
    const initial_position::Int64
    const count::UInt16
    index::UInt16
    function TensorStreamHeaderMessageSliceEncoder(buffer::T, offset::Integer, position_ptr::Ref{Int64},
        initial_position::Int64, count::Integer, index::Integer) where {T}
        new{T}(buffer, offset, position_ptr, initial_position, count, index)
    end
end

@inline function TensorStreamHeaderMessageSliceDecoder(buffer, position_ptr, acting_version)
    dimensions = GroupSizeEncoding(buffer, position_ptr[])
    position_ptr[] += 4
    return TensorStreamHeaderMessageSliceDecoder(buffer, 0, position_ptr, blockLength(dimensions),
        acting_version, numInGroup(dimensions), 0)
end

@inline function TensorStreamHeaderMessageSliceEncoder(buffer, count, position_ptr)
    if count > 65534
        error("count outside of allowed range")
    end
    dimensions = GroupSizeEncoding(buffer, position_ptr[])
    blockLength!(dimensions, UInt16(0x8))
    numInGroup!(dimensions, count)
    initial_position = position_ptr[]
    position_ptr[] += 4
    return TensorStreamHeaderMessageSliceEncoder(buffer, 0, position_ptr, initial_position, count, 0)
end

sbe_header_size(::TensorStreamHeaderMessageSlice) = 4
sbe_block_length(::TensorStreamHeaderMessageSlice) = UInt16(0x8)
sbe_acting_block_length(g::TensorStreamHeaderMessageSliceDecoder) = g.block_length
sbe_acting_block_length(g::TensorStreamHeaderMessageSliceEncoder) = UInt16(0x8)
sbe_acting_version(g::TensorStreamHeaderMessageSliceDecoder) = g.acting_version
sbe_acting_version(::TensorStreamHeaderMessageSliceEncoder) = UInt16(0x0)
sbe_position(g::TensorStreamHeaderMessageSlice) = g.position_ptr[]
@inline sbe_position!(g::TensorStreamHeaderMessageSlice, position) = g.position_ptr[] = position
sbe_position_ptr(g::TensorStreamHeaderMessageSlice) = g.position_ptr
@inline function next!(g::TensorStreamHeaderMessageSlice)
    if g.index >= g.count
        error("index >= count")
    end
    g.offset = sbe_position(g)
    sbe_position!(g, g.offset + sbe_acting_block_length(g))
    g.index += 1
    return g
end
function Base.iterate(g::TensorStreamHeaderMessageSlice, state=nothing)
    if g.index < g.count
        g.offset = sbe_position(g)
        sbe_position!(g, g.offset + sbe_acting_block_length(g))
        g.index += 1
        return g, state
    else
        return nothing
    end
end
Base.eltype(::Type{<:TensorStreamHeaderMessageSlice}) = TensorStreamHeaderMessageSlice
Base.isdone(g::TensorStreamHeaderMessageSlice, state=nothing) = g.index >= g.count
Base.length(g::TensorStreamHeaderMessageSlice) = g.count

function reset_count_to_index!(g::TensorStreamHeaderMessageSliceEncoder)
    g.count = g.index
    dimensions = GroupSizeEncoding(g.buffer, g.initial_position)
    numInGroup!(dimensions, g.count)
    return g.count
end

function start_meta_attribute(::TensorStreamHeaderMessageSlice, meta_attribute)
    meta_attribute === :presence && return Symbol("required")
    return Symbol("")
end
start_id(::TensorStreamHeaderMessageSlice) = UInt16(0x1)
start_since_version(::TensorStreamHeaderMessageSlice) = UInt16(0x0)
start_in_acting_version(m::TensorStreamHeaderMessageSlice) = sbe_acting_version(m) >= UInt16(0x0)
start_encoding_offset(::TensorStreamHeaderMessageSlice) = 0
start_null_value(::TensorStreamHeaderMessageSlice) = Int32(-2147483648)
start_min_value(::TensorStreamHeaderMessageSlice) = Int32(-2147483647)
start_max_value(::TensorStreamHeaderMessageSlice) = Int32(2147483647)
start_encoding_length(::TensorStreamHeaderMessageSlice) = 4

@inline function start(m::TensorStreamHeaderMessageSliceDecoder)
    return decode_le(Int32, m.buffer, m.offset + 0)
end
@inline start!(m::TensorStreamHeaderMessageSliceEncoder, value) = encode_le(Int32, m.buffer, m.offset + 0, value)

function stop_meta_attribute(::TensorStreamHeaderMessageSlice, meta_attribute)
    meta_attribute === :presence && return Symbol("required")
    return Symbol("")
end
stop_id(::TensorStreamHeaderMessageSlice) = UInt16(0x2)
stop_since_version(::TensorStreamHeaderMessageSlice) = UInt16(0x0)
stop_in_acting_version(m::TensorStreamHeaderMessageSlice) = sbe_acting_version(m) >= UInt16(0x0)
stop_encoding_offset(::TensorStreamHeaderMessageSlice) = 4
stop_null_value(::TensorStreamHeaderMessageSlice) = Int32(-2147483648)
stop_min_value(::TensorStreamHeaderMessageSlice) = Int32(-2147483647)
stop_max_value(::TensorStreamHeaderMessageSlice) = Int32(2147483647)
stop_encoding_length(::TensorStreamHeaderMessageSlice) = 4

@inline function stop(m::TensorStreamHeaderMessageSliceDecoder)
    return decode_le(Int32, m.buffer, m.offset + 4)
end
@inline stop!(m::TensorStreamHeaderMessageSliceEncoder, value) = encode_le(Int32, m.buffer, m.offset + 4, value)

function show(io::IO, writer::TensorStreamHeaderMessageSlice{T}) where {T}
    println(io, "TensorStreamHeaderMessageSlice view over a type $T")
    print(io, "start: ")
    print(io, start(writer))

    println(io)
    print(io, "stop: ")
    print(io, stop(writer))

end

@inline function sbe_skip!(m::TensorStreamHeaderMessageSliceDecoder)
    
    return
end

@inline function slice(m::TensorStreamHeaderMessage)
    return TensorStreamHeaderMessageSliceDecoder(m.buffer, sbe_position_ptr(m), sbe_acting_version(m))
end

@inline function slice!(m::TensorStreamHeaderMessage, count)
    return TensorStreamHeaderMessageSliceEncoder(m.buffer, count, sbe_position_ptr(m))
end
slice_group_count!(m::TensorStreamHeaderMessageEncoder, count) = slice!(m, count)
slice_id(::TensorStreamHeaderMessage) = 11
slice_since_version(::TensorStreamHeaderMessage) = 0
slice_in_acting_version(m::TensorStreamHeaderMessage) = sbe_acting_version(m) >= 0

export TensorStreamHeaderMessageMetadata, TensorStreamHeaderMessageMetadataDecoder, TensorStreamHeaderMessageMetadataEncoder
abstract type TensorStreamHeaderMessageMetadata{T} end

mutable struct TensorStreamHeaderMessageMetadataDecoder{T<:AbstractArray{UInt8}} <: TensorStreamHeaderMessageMetadata{T}
    const buffer::T
    offset::Int64
    const position_ptr::Base.RefValue{Int64}
    const block_length::UInt16
    const acting_version::UInt16
    const count::UInt16
    index::UInt16
    function TensorStreamHeaderMessageMetadataDecoder(buffer::T, offset::Integer, position_ptr::Ref{Int64},
        block_length::Integer, acting_version::Integer,
        count::Integer, index::Integer) where {T}
        new{T}(buffer, offset, position_ptr, block_length, acting_version, count, index)
    end
end

mutable struct TensorStreamHeaderMessageMetadataEncoder{T<:AbstractArray{UInt8}} <: TensorStreamHeaderMessageMetadata{T}
    const buffer::T
    offset::Int64
    const position_ptr::Base.RefValue{Int64}
    const initial_position::Int64
    const count::UInt16
    index::UInt16
    function TensorStreamHeaderMessageMetadataEncoder(buffer::T, offset::Integer, position_ptr::Ref{Int64},
        initial_position::Int64, count::Integer, index::Integer) where {T}
        new{T}(buffer, offset, position_ptr, initial_position, count, index)
    end
end

@inline function TensorStreamHeaderMessageMetadataDecoder(buffer, position_ptr, acting_version)
    dimensions = GroupSizeEncoding(buffer, position_ptr[])
    position_ptr[] += 4
    return TensorStreamHeaderMessageMetadataDecoder(buffer, 0, position_ptr, blockLength(dimensions),
        acting_version, numInGroup(dimensions), 0)
end

@inline function TensorStreamHeaderMessageMetadataEncoder(buffer, count, position_ptr)
    if count > 65534
        error("count outside of allowed range")
    end
    dimensions = GroupSizeEncoding(buffer, position_ptr[])
    blockLength!(dimensions, UInt16(0x1))
    numInGroup!(dimensions, count)
    initial_position = position_ptr[]
    position_ptr[] += 4
    return TensorStreamHeaderMessageMetadataEncoder(buffer, 0, position_ptr, initial_position, count, 0)
end

sbe_header_size(::TensorStreamHeaderMessageMetadata) = 4
sbe_block_length(::TensorStreamHeaderMessageMetadata) = UInt16(0x1)
sbe_acting_block_length(g::TensorStreamHeaderMessageMetadataDecoder) = g.block_length
sbe_acting_block_length(g::TensorStreamHeaderMessageMetadataEncoder) = UInt16(0x1)
sbe_acting_version(g::TensorStreamHeaderMessageMetadataDecoder) = g.acting_version
sbe_acting_version(::TensorStreamHeaderMessageMetadataEncoder) = UInt16(0x0)
sbe_position(g::TensorStreamHeaderMessageMetadata) = g.position_ptr[]
@inline sbe_position!(g::TensorStreamHeaderMessageMetadata, position) = g.position_ptr[] = position
sbe_position_ptr(g::TensorStreamHeaderMessageMetadata) = g.position_ptr
@inline function next!(g::TensorStreamHeaderMessageMetadata)
    if g.index >= g.count
        error("index >= count")
    end
    g.offset = sbe_position(g)
    sbe_position!(g, g.offset + sbe_acting_block_length(g))
    g.index += 1
    return g
end
function Base.iterate(g::TensorStreamHeaderMessageMetadata, state=nothing)
    if g.index < g.count
        g.offset = sbe_position(g)
        sbe_position!(g, g.offset + sbe_acting_block_length(g))
        g.index += 1
        return g, state
    else
        return nothing
    end
end
Base.eltype(::Type{<:TensorStreamHeaderMessageMetadata}) = TensorStreamHeaderMessageMetadata
Base.isdone(g::TensorStreamHeaderMessageMetadata, state=nothing) = g.index >= g.count
Base.length(g::TensorStreamHeaderMessageMetadata) = g.count

function reset_count_to_index!(g::TensorStreamHeaderMessageMetadataEncoder)
    g.count = g.index
    dimensions = GroupSizeEncoding(g.buffer, g.initial_position)
    numInGroup!(dimensions, g.count)
    return g.count
end

function format_meta_attribute(::TensorStreamHeaderMessageMetadata, meta_attribute)
    meta_attribute === :presence && return Symbol("required")
    return Symbol("")
end
format_id(::TensorStreamHeaderMessageMetadata) = UInt16(0x1)
format_since_version(::TensorStreamHeaderMessageMetadata) = UInt16(0x0)
format_in_acting_version(m::TensorStreamHeaderMessageMetadata) = sbe_acting_version(m) >= UInt16(0x0)
format_encoding_offset(::TensorStreamHeaderMessageMetadata) = 0
format_encoding_length(::TensorStreamHeaderMessageMetadata) = 1
@inline function format(m::TensorStreamHeaderMessageMetadataDecoder, ::Type{Integer})
    return decode_le(Int8, m.buffer, m.offset + 0)
end
@inline function format(m::TensorStreamHeaderMessageMetadataDecoder)
    return Format.SbeEnum(decode_le(Int8, m.buffer, m.offset + 0))
end
@inline format!(m::TensorStreamHeaderMessageMetadataEncoder, value::Format.SbeEnum) = encode_le(Int8, m.buffer, m.offset + 0, Int8(value))

function key_meta_attribute(::TensorStreamHeaderMessageMetadata, meta_attribute)
    meta_attribute === :presence && return Symbol("required")
    return Symbol("")
end

key_character_encoding(::TensorStreamHeaderMessageMetadata) = "UTF-8"
key_in_acting_version(m::TensorStreamHeaderMessageMetadata) = sbe_acting_version(m) >= 0
key_id(::TensorStreamHeaderMessageMetadata) = 3
key_header_length(::TensorStreamHeaderMessageMetadata) = 4

@inline function key_length(m::TensorStreamHeaderMessageMetadata)
    return decode_le(UInt32, m.buffer, sbe_position(m))
end

@inline function key_length!(m::TensorStreamHeaderMessageMetadataEncoder, n)
    @boundscheck n > 1073741824 && throw(ArgumentError("length exceeds schema limit"))
    @boundscheck checkbounds(m.buffer, sbe_position(m) + 4 + n)
    return encode_le(UInt32, m.buffer, sbe_position(m), n)
end

@inline function skip_key!(m::TensorStreamHeaderMessageMetadataDecoder)
    len = key_length(m)
    pos = sbe_position(m) + 4
    sbe_position!(m, pos + len)
    return len
end

@inline function key(m::TensorStreamHeaderMessageMetadataDecoder)
    len = key_length(m)
    pos = sbe_position(m) + 4
    sbe_position!(m, pos + len)
    return view(m.buffer, pos+1:pos+len)
end

@inline key(m::TensorStreamHeaderMessageMetadataDecoder, ::Type{AbstractArray{T}}) where {T<:Real} = reinterpret(T, key(m))
@inline key(m::TensorStreamHeaderMessageMetadataDecoder, ::Type{NTuple{N,T}}) where {N,T<:Real} = (x = reinterpret(T, key(m)); ntuple(i -> x[i], Val(N)))
@inline key(m::TensorStreamHeaderMessageMetadataDecoder, ::Type{T}) where {T<:AbstractString} = StringView(rstrip_nul(key(m)))
@inline key(m::TensorStreamHeaderMessageMetadataDecoder, ::Type{T}) where {T<:Symbol} = Symbol(key(m, StringView))
@inline key(m::TensorStreamHeaderMessageMetadataDecoder, ::Type{T}) where {T<:Real} = reinterpret(T, key(m))[]
@inline key(m::TensorStreamHeaderMessageMetadataDecoder, ::Type{T}) where {T<:Nothing} = (skip_key!(m); nothing)

@inline function key_buffer!(m::TensorStreamHeaderMessageMetadataEncoder, len)
    key_length!(m, len)
    pos = sbe_position(m) + 4
    sbe_position!(m, pos + len)
    return view(m.buffer, pos+1:pos+len)
end

@inline function key!(m::TensorStreamHeaderMessageMetadataEncoder, src::AbstractArray)
    len = sizeof(src)
    key_length!(m, len)
    pos = sbe_position(m) + 4
    sbe_position!(m, pos + len)
    dest = view(m.buffer, pos+1:pos+len)
    copyto!(dest, reinterpret(UInt8, src))
end

@inline function key!(m::TensorStreamHeaderMessageMetadataEncoder, src::NTuple)
    len = sizeof(src)
    key_length!(m, len)
    pos = sbe_position(m) + 4
    sbe_position!(m, pos + len)
    dest = view(m.buffer, pos+1:pos+len)
    copyto!(dest, reinterpret(NTuple{len,UInt8}, src))
end

@inline function key!(m::TensorStreamHeaderMessageMetadataEncoder, src::AbstractString)
    len = sizeof(src)
    key_length!(m, len)
    pos = sbe_position(m) + 4
    sbe_position!(m, pos + len)
    dest = view(m.buffer, pos+1:pos+len)
    copyto!(dest, codeunits(src))
end

@inline key!(m::TensorStreamHeaderMessageMetadataEncoder, src::Symbol) = key!(m, to_string(src))
@inline key!(m::TensorStreamHeaderMessageMetadataEncoder, src::StaticString) = key!(m, Tuple(src))
@inline key!(m::TensorStreamHeaderMessageMetadataEncoder, src::Real) = key!(m, Tuple(src))
@inline key!(m::TensorStreamHeaderMessageMetadataEncoder, ::Nothing) = key_buffer!(m, 0)

function value_meta_attribute(::TensorStreamHeaderMessageMetadata, meta_attribute)
    meta_attribute === :presence && return Symbol("required")
    return Symbol("")
end

value_character_encoding(::TensorStreamHeaderMessageMetadata) = "null"
value_in_acting_version(m::TensorStreamHeaderMessageMetadata) = sbe_acting_version(m) >= 0
value_id(::TensorStreamHeaderMessageMetadata) = 4
value_header_length(::TensorStreamHeaderMessageMetadata) = 4

@inline function value_length(m::TensorStreamHeaderMessageMetadata)
    return decode_le(UInt32, m.buffer, sbe_position(m))
end

@inline function value_length!(m::TensorStreamHeaderMessageMetadataEncoder, n)
    @boundscheck n > 1073741824 && throw(ArgumentError("length exceeds schema limit"))
    @boundscheck checkbounds(m.buffer, sbe_position(m) + 4 + n)
    return encode_le(UInt32, m.buffer, sbe_position(m), n)
end

@inline function skip_value!(m::TensorStreamHeaderMessageMetadataDecoder)
    len = value_length(m)
    pos = sbe_position(m) + 4
    sbe_position!(m, pos + len)
    return len
end

@inline function value(m::TensorStreamHeaderMessageMetadataDecoder)
    len = value_length(m)
    pos = sbe_position(m) + 4
    sbe_position!(m, pos + len)
    return view(m.buffer, pos+1:pos+len)
end

@inline value(m::TensorStreamHeaderMessageMetadataDecoder, ::Type{AbstractArray{T}}) where {T<:Real} = reinterpret(T, value(m))
@inline value(m::TensorStreamHeaderMessageMetadataDecoder, ::Type{NTuple{N,T}}) where {N,T<:Real} = (x = reinterpret(T, value(m)); ntuple(i -> x[i], Val(N)))
@inline value(m::TensorStreamHeaderMessageMetadataDecoder, ::Type{T}) where {T<:AbstractString} = StringView(rstrip_nul(value(m)))
@inline value(m::TensorStreamHeaderMessageMetadataDecoder, ::Type{T}) where {T<:Symbol} = Symbol(value(m, StringView))
@inline value(m::TensorStreamHeaderMessageMetadataDecoder, ::Type{T}) where {T<:Real} = reinterpret(T, value(m))[]
@inline value(m::TensorStreamHeaderMessageMetadataDecoder, ::Type{T}) where {T<:Nothing} = (skip_value!(m); nothing)

@inline function value_buffer!(m::TensorStreamHeaderMessageMetadataEncoder, len)
    value_length!(m, len)
    pos = sbe_position(m) + 4
    sbe_position!(m, pos + len)
    return view(m.buffer, pos+1:pos+len)
end

@inline function value!(m::TensorStreamHeaderMessageMetadataEncoder, src::AbstractArray)
    len = sizeof(src)
    value_length!(m, len)
    pos = sbe_position(m) + 4
    sbe_position!(m, pos + len)
    dest = view(m.buffer, pos+1:pos+len)
    copyto!(dest, reinterpret(UInt8, src))
end

@inline function value!(m::TensorStreamHeaderMessageMetadataEncoder, src::NTuple)
    len = sizeof(src)
    value_length!(m, len)
    pos = sbe_position(m) + 4
    sbe_position!(m, pos + len)
    dest = view(m.buffer, pos+1:pos+len)
    copyto!(dest, reinterpret(NTuple{len,UInt8}, src))
end

@inline function value!(m::TensorStreamHeaderMessageMetadataEncoder, src::AbstractString)
    len = sizeof(src)
    value_length!(m, len)
    pos = sbe_position(m) + 4
    sbe_position!(m, pos + len)
    dest = view(m.buffer, pos+1:pos+len)
    copyto!(dest, codeunits(src))
end

@inline value!(m::TensorStreamHeaderMessageMetadataEncoder, src::Symbol) = value!(m, to_string(src))
@inline value!(m::TensorStreamHeaderMessageMetadataEncoder, src::StaticString) = value!(m, Tuple(src))
@inline value!(m::TensorStreamHeaderMessageMetadataEncoder, src::Real) = value!(m, Tuple(src))
@inline value!(m::TensorStreamHeaderMessageMetadataEncoder, ::Nothing) = value_buffer!(m, 0)

function show(io::IO, writer::TensorStreamHeaderMessageMetadata{T}) where {T}
    println(io, "TensorStreamHeaderMessageMetadata view over a type $T")
    print(io, "format: ")
    print(io, format(writer))

    println(io)
    print(io, "key: ")
    print(io, key(writer, StringView))

    println(io)
    print(io, "value: ")
    print(io, skip_value!(writer))
    print(io, " bytes of raw data")

end

@inline function sbe_skip!(m::TensorStreamHeaderMessageMetadataDecoder)
    
    skip_key!(m)
    skip_value!(m)
    return
end

@inline function metadata(m::TensorStreamHeaderMessage)
    return TensorStreamHeaderMessageMetadataDecoder(m.buffer, sbe_position_ptr(m), sbe_acting_version(m))
end

@inline function metadata!(m::TensorStreamHeaderMessage, count)
    return TensorStreamHeaderMessageMetadataEncoder(m.buffer, count, sbe_position_ptr(m))
end
metadata_group_count!(m::TensorStreamHeaderMessageEncoder, count) = metadata!(m, count)
metadata_id(::TensorStreamHeaderMessage) = 12
metadata_since_version(::TensorStreamHeaderMessage) = 0
metadata_in_acting_version(m::TensorStreamHeaderMessage) = sbe_acting_version(m) >= 0

function dims_meta_attribute(::TensorStreamHeaderMessage, meta_attribute)
    meta_attribute === :presence && return Symbol("required")
    return Symbol("")
end

dims_character_encoding(::TensorStreamHeaderMessage) = "null"
dims_in_acting_version(m::TensorStreamHeaderMessage) = sbe_acting_version(m) >= 0
dims_id(::TensorStreamHeaderMessage) = 10
dims_header_length(::TensorStreamHeaderMessage) = 4

@inline function dims_length(m::TensorStreamHeaderMessage)
    return decode_le(UInt32, m.buffer, sbe_position(m))
end

@inline function dims_length!(m::TensorStreamHeaderMessageEncoder, n)
    @boundscheck n > 1073741824 && throw(ArgumentError("length exceeds schema limit"))
    @boundscheck checkbounds(m.buffer, sbe_position(m) + 4 + n)
    return encode_le(UInt32, m.buffer, sbe_position(m), n)
end

@inline function skip_dims!(m::TensorStreamHeaderMessageDecoder)
    len = dims_length(m)
    pos = sbe_position(m) + 4
    sbe_position!(m, pos + len)
    return len
end

@inline function dims(m::TensorStreamHeaderMessageDecoder)
    len = dims_length(m)
    pos = sbe_position(m) + 4
    sbe_position!(m, pos + len)
    return view(m.buffer, pos+1:pos+len)
end

@inline dims(m::TensorStreamHeaderMessageDecoder, ::Type{AbstractArray{T}}) where {T<:Real} = reinterpret(T, dims(m))
@inline dims(m::TensorStreamHeaderMessageDecoder, ::Type{NTuple{N,T}}) where {N,T<:Real} = (x = reinterpret(T, dims(m)); ntuple(i -> x[i], Val(N)))
@inline dims(m::TensorStreamHeaderMessageDecoder, ::Type{T}) where {T<:AbstractString} = StringView(rstrip_nul(dims(m)))
@inline dims(m::TensorStreamHeaderMessageDecoder, ::Type{T}) where {T<:Symbol} = Symbol(dims(m, StringView))
@inline dims(m::TensorStreamHeaderMessageDecoder, ::Type{T}) where {T<:Real} = reinterpret(T, dims(m))[]
@inline dims(m::TensorStreamHeaderMessageDecoder, ::Type{T}) where {T<:Nothing} = (skip_dims!(m); nothing)

@inline function dims_buffer!(m::TensorStreamHeaderMessageEncoder, len)
    dims_length!(m, len)
    pos = sbe_position(m) + 4
    sbe_position!(m, pos + len)
    return view(m.buffer, pos+1:pos+len)
end

@inline function dims!(m::TensorStreamHeaderMessageEncoder, src::AbstractArray)
    len = sizeof(src)
    dims_length!(m, len)
    pos = sbe_position(m) + 4
    sbe_position!(m, pos + len)
    dest = view(m.buffer, pos+1:pos+len)
    copyto!(dest, reinterpret(UInt8, src))
end

@inline function dims!(m::TensorStreamHeaderMessageEncoder, src::NTuple)
    len = sizeof(src)
    dims_length!(m, len)
    pos = sbe_position(m) + 4
    sbe_position!(m, pos + len)
    dest = view(m.buffer, pos+1:pos+len)
    copyto!(dest, reinterpret(NTuple{len,UInt8}, src))
end

@inline function dims!(m::TensorStreamHeaderMessageEncoder, src::AbstractString)
    len = sizeof(src)
    dims_length!(m, len)
    pos = sbe_position(m) + 4
    sbe_position!(m, pos + len)
    dest = view(m.buffer, pos+1:pos+len)
    copyto!(dest, codeunits(src))
end

@inline dims!(m::TensorStreamHeaderMessageEncoder, src::Symbol) = dims!(m, to_string(src))
@inline dims!(m::TensorStreamHeaderMessageEncoder, src::StaticString) = dims!(m, Tuple(src))
@inline dims!(m::TensorStreamHeaderMessageEncoder, src::Real) = dims!(m, Tuple(src))
@inline dims!(m::TensorStreamHeaderMessageEncoder, ::Nothing) = dims_buffer!(m, 0)

function show(io::IO, m::TensorStreamHeaderMessage{T}) where {T}
    println(io, "TensorStreamHeaderMessage view over a type $T")
    println(io, "SbeBlockLength: ", sbe_block_length(m))
    println(io, "SbeTemplateId:  ", sbe_template_id(m))
    println(io, "SbeSchemaId:    ", sbe_schema_id(m))
    println(io, "SbeSchemaVersion: ", sbe_schema_version(m))

    writer = TensorStreamHeaderMessageDecoder(sbe_buffer(m), sbe_offset(m), Ref(0),
        sbe_block_length(m), sbe_schema_version(m))
    print(io, "header: ")
    show(io, header(writer))

    println(io)
    print(io, "sequencenumber: ")
    print(io, sequencenumber(writer))

    println(io)
    print(io, "format: ")
    print(io, format(writer))

    println(io)
    print(io, "majorOrder: ")
    print(io, majorOrder(writer))

    println(io)
    println(io, "Slice:")
    for group in slice(writer)
        show(io, group)
        println(io)
    end
    println(io)
    println(io, "Metadata:")
    for group in metadata(writer)
        show(io, group)
        println(io)
    end
    println(io)
    print(io, "dims: ")
    print(io, skip_dims!(writer))
    print(io, " bytes of raw data")

    nothing
end

@inline function sbe_skip!(m::TensorStreamHeaderMessageDecoder)
    sbe_rewind!(m)
    for group in slice(m)
        sbe_skip!(group)
    end
    for group in metadata(m)
        sbe_skip!(group)
    end
    skip_dims!(m)
    return
end
